<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8" />
  <meta name="description" content="AutoCodeBench: Large Language Models are Automatic Code Benchmark Generators" />
  <meta name="keywords" content="Multilingual, Code, Large Language Models, LLM, Code LLM, Evaluation, Benchmark" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>
    AutoCodeBench: Large Language Models are Automatic Code Benchmark Generators
  </title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <!-- <script
      async
      src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"
    ></script>
    <script>
      window.dataLayer = window.dataLayer || []

      function gtag() {
        dataLayer.push(arguments)
      }

      gtag("js", new Date())

      gtag("config", "G-PYVRSFMDRL")
    </script> -->

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet" />

  <link rel="stylesheet" href="./css/bulma.min.css" />
  <link rel="stylesheet" href="./css/bulma-carousel.min.css" />
  <link rel="stylesheet" href="./css/bulma-slider.min.css" />
  <link rel="stylesheet" href="./css/fontawesome.all.min.css" />
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css" />
  <link rel="stylesheet" href="./css/index.css" />
  <link rel="icon" href="./images/favicon.svg" />

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./js/fontawesome.all.min.js"></script>
  <script src="./js/bulma-carousel.min.js"></script>
  <script src="./js/bulma-slider.min.js"></script>
  <script src="./js/index.js"></script>
  
  <!-- Navbar Toggle Script -->
  <script>
    document.addEventListener('DOMContentLoaded', () => {
      // Get all "navbar-burger" elements
      const $navbarBurgers = Array.prototype.slice.call(document.querySelectorAll('.navbar-burger'), 0);

      // Add a click event on each of them
      $navbarBurgers.forEach( el => {
        el.addEventListener('click', () => {
          // Get the target from the "data-target" attribute
          const target = el.dataset.target;
          const $target = document.getElementById(target);

          // Toggle the "is-active" class on both the "navbar-burger" and the "navbar-menu"
          el.classList.toggle('is-active');
          $target.classList.toggle('is-active');
        });
      });
    });
  </script>
</head>

<body>

  <!-- Navigation Menu -->
  <div style="position: absolute; top: 1rem; right: 18rem; z-index: 100;">
    <div class="dropdown is-hoverable is-right">
      <div class="dropdown-trigger">
        <button class="button is-primary is-outlined is-small" aria-haspopup="true" aria-controls="dropdown-menu">
          <span>More Projects</span>
          <span class="icon is-small">
            <i class="fas fa-angle-down" aria-hidden="true"></i>
          </span>
        </button>
      </div>
      <div class="dropdown-menu" id="dropdown-menu" role="menu">
        <div class="dropdown-content">
          <a href="https://artifactsbenchmark.github.io/" target="_blank" class="dropdown-item">
            <span class="icon-text">
              <span class="icon">
                <i class="fas fa-external-link-alt"></i>
              </span>
              <span>ArtifactsBench</span>
            </span>
          </a>
          <a href="https://github.com/Tencent-Hunyuan/DRIVE-RLVR" target="_blank" class="dropdown-item">
            <span class="icon-text">
              <span class="icon">
                <i class="fas fa-external-link-alt"></i>
              </span>
              <span>DRIVE-RLVR</span>
            </span>
          </a>
        </div>
      </div>
    </div>
  </div>

  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">
              AutoCodeBench: Large Language Models are Automatic Code Benchmark Generators
            </h1>
            
       <div class="is-size-5 publication-authors">
              <span class="author-block">
                <a href="">Jason Chou</a><sup>*</sup>,</span>
              <span class="author-block">
                <a href="">Ao Liu</a><sup>*</sup>,</span>
              <span class="author-block">
                <a href="">Yuchi Deng</a>,</span>
              <span class="author-block">
                <a href="">Zhiying Zeng</a>,</span>
              <span class="author-block">
                <a href="">Tao Zhang</a>,</span>
              <span class="author-block">
                <a href="">Haotian Zhu</a>,</span>
                <span class="author-block">
                <a href="">Jianwei Cai</a>,</span>
                </div> 
        <div class="is-size-5 publication-authors">
              
              <span class="author-block">
                <a href="">Yue Mao</a>,</span>
              <span class="author-block">
                <a href="">Chenchen Zhang</a>,</span>
              <span class="author-block">
                <a href="">Lingyun Tan</a>,</span>
              <span class="author-block">
                <a href="">Ziyan Xu</a>,</span>
              <span class="author-block">
                <a href="">Bohui Zhai</a>,</span>
              <span class="author-block">
                <a href="">Hengyi Liu</a>,</span>
              <span class="author-block">
                <a href="">Speed Zhu</a>,</span>
            </div>
            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <a href="">Wiggin Zhou</a><sup>â€ </sup></span>
              <span class="author-block">
                <a href="">Fengzong Lian</a><sup>â€ </sup></span>
            </div>
            <div class="is-size-5 publication-authors">
              <span class="author-block">
                jasonchou9877@gmail.com; {nickaliu,wigginzhou,faxonlian}@tencent.com</span>
            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block"><strong>Hunyuan Team, Tencent</strong></span>
            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block"><sup>*</sup>Equal Contributions</span>
              <span class="author-block"><sup>â€ </sup>Corresponding Authors</span>
            </div>

            <div class="column has-text-centered">
              <div class="publication-links">
                <!-- PDF Link. -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2508.09101" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                    </span>
                    <span>Paper</span>
                  </a>
                </span>
                <span class="link-block">
                  <a href="https://github.com/Tencent-Hunyuan/AutoCodeBenchmark"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>
                <!-- Dataset Link. -->
                <span class="link-block">
                  <a href="https://huggingface.co/datasets/tencent/AutoCodeBenchmark"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="far fa-images"></i>
                    </span>
                    <span>Data</span>
                  </a>
                </span>
                <span class="link-block">
                  <a href="https://hub.docker.com/r/hunyuansandbox/multi-language-sandbox"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-box"></i>
                    </span>
                    <span>Sandbox</span>
                  </a>
                </span>
                <!-- Leaderboard Link. -->
                <span class="link-block">
                  <a href="leaderboard.html" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fa fa-trophy"></i>
                    </span>
                    <span>Leaderboard</span>
                  </a>
                </span>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <!-- <section class="hero teaser">
    <div class="container is-max-desktop">
      <div class="hero-body">
        <div class="columns is-centered">
          <img src="./images/autocodebench_intro.png" alt="Teaser" class="teaser-image center" width="80%" />
        </div>
      </div>
    </div>
  </section> -->


  

  <section class="section">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column is-8">
          <h2 class="title is-3 has-text-centered mb-4">ðŸ“° News</h2>
          
          <div class="content">


            <div class="news-item mb-4">
              <span class="icon has-text-success news-icon">
                <i class="fas fa-wrench"></i>
              </span>
              <div class="news-content">
                <strong>2026.02.17</strong> ðŸ”§ - We have updated the v2 version of AutoCodeBench and fixed several bugs, which led to performance improvements across all models. The dataset is available in <a href="https://huggingface.co/datasets/tencent/AutoCodeBenchmark/blob/main/autocodebench-v2-260217.jsonl">autocodebench-v2-260217.jsonl</a>.
              </div>
            </div>


            <div class="news-item mb-4">
              <span class="icon has-text-success news-icon">
                <i class="fas fa-rocket"></i>
              </span>
              <div class="news-content">
                <strong>2025.12.04</strong> ðŸš€ - We released <strong>AutoCodeBench-V2</strong>, built on the original dataset and iteratively refined through top proprietary models and a sandbox to produce 1,000 higher-quality problems! The <strong>leaderboard and evaluation tutorial</strong> are available in <a href="https://github.com/Tencent-Hunyuan/AutoCodeBenchmark/tree/main/AutoCodeBench-V2">AutoCodeBench-V2</a>!
              </div>
            </div>

            <div class="news-item mb-4">
              <span class="icon has-text-success news-icon">
                <i class="fas fa-book"></i>
              </span>
              <div class="news-content">
                <strong>2025.12.04</strong> ðŸ“š - We released <strong>AutoCodeInstruct</strong>, a large-scale multilingual dataset equipped with golden answers distilled from DeepSeek-V3-0324, and filtered using Qwen2.5-Coder-7B/32B-Instruct to create two versions suitable for RL and SFT training! The dataset is available at <a href="https://huggingface.co/datasets/tencent/AutoCodeBenchmark/blob/main/autocodeinstruct_v3answer_qwen32b.jsonl">autocodeinstruct_v3answer_qwen32b.jsonl</a> and <a href="https://huggingface.co/datasets/tencent/AutoCodeBenchmark/blob/main/autocodeinstruct_v3answer_qwen7b.jsonl">autocodeinstruct_v3answer_qwen7b.jsonl</a>. Experimental details can be found in the <a href="https://openreview.net/pdf?id=fN0MED2Idq">paper</a>.
              </div>
            </div>

            <div class="news-item mb-4">
              <span class="icon has-text-success news-icon">
                <i class="fas fa-code"></i>
              </span>
              <div class="news-content">
                <strong>2025.08.15</strong> ðŸŽ‰ - We released AutoCodeGen, AutoCodeBench series, and Multi-lingual Sandbox!
              </div>
            </div>

            <div class="news-item mb-4">
              <span class="icon has-text-info news-icon">
                <i class="fas fa-file-alt"></i>
              </span>
              <div class="news-content">
                <strong>2025.08.13</strong> ðŸ“„ - We published our <a href="https://arxiv.org/abs/2411.02906">arXiv paper</a>!
              </div>
            </div>
          </div>

        </div>
      </div>
    </div>
  </section>




  <section class="section">
    <div class="container is-max-desktop">
      <!-- Abstract. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Introduction</h2>
          <div class="content has-text-justified">
            <div class="content has-text-justified">
              <p>
                <strong>AutoCodeGen</strong>. We propose an automated workflow based on LLM-Sandbox interaction, where LLMs generate test inputs and obtain test outputs through the sandbox to create high-quality code generation datasets.
              </p>
              <p>
                <strong>AutoCodeBench</strong>. We introduce AutoCodeBench, a large-scale code generation benchmark with 3,920 problems, evenly distributed across 20 programming languages. It features high difficulty, practicality, and diversity, and is designed to measure the absolute multilingual performance of models.
              </p>
              <p>
                <strong>AutoCodeBench-Lite</strong>. Based on the evaluation results of over 30 open-source and closed-source models on AutoCodeBench, we select 1,586 problems that were successfully solved by at least two models. This subset, AutoCodeBench-Lite, is used to measure performance differences between models.
              </p>
              <p>
                <strong>AutoCodeBench-Complete</strong>. We select 1,000 problems from AutoCodeBench-Lite and use 3-shot prompting to construct AutoCodeBench-Complete, a completion-style code generation benchmark designed to assess the performance of base models.
              </p>
              <p>
                <strong>MultiLanguageSandbox</strong>. A robust, secure, and high-performance multi-language code execution sandbox service that provides comprehensive support for compilation and execution across more than 30 programming languages.
              </p>



            </div>
          </div>
        </div>
      </div>
      <!--/ Abstract. -->
    </div>
  </section>
  <section class="section">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">AutoCodeGen</h2>
          <div class="content has-text-justified">
            <div class="columns is-centered">
              <img src="./images/autocodegen.png" alt="HumanEval Overfitting" class="teaser-image center" width="90%"
                height="90%" />
            </div>
            <p>
              The core innovation of AutoCodeGen lies in having LLMs generate test inputs, execute them in a sandbox to obtain test outputs, and generate programming problems in reverse. This approach is more efficient, scalable, and ensures better test case coverage compared to existing methods like KodCode and CodeI/O.
            </p>
          </div>
        </div>
      </div>
  </section>
  <section class="section">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">AutoCodeBench</h2>
          <div class="content has-text-justified">
            <div class="columns is-centered">
              <img src="./images/autocodebench_intro.png" alt="HumanEval Overfitting" class="teaser-image center" width="90%"
                height="90%" />
            </div>

            <div class="columns is-centered">
              <img src="./images/autocodebench_statistic.png" alt="HumanEval Overfitting" class="teaser-image center" width="90%"
                height="90%" />
            </div>

            <div class="columns is-centered">
              <img src="./images/autocodebench_distribution.png" alt="HumanEval Overfitting" class="teaser-image center" width="90%"
                height="90%" />
            </div>
            <!-- <p>
              AutoCodeBench is a large-scale code generation benchmark with 3,920 problems, evenly distributed across 20 programming languages. It features high difficulty, practicality, and diversity, and is designed to measure the absolute multilingual performance of models.
            </p> -->
          </div>
        </div>
      </div>  
  </section>
<section class="section">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Experimental Results</h2>
          <div class="content has-text-justified">
            <div class="columns is-centered">
              <img src="./images/exp_acb.png" alt="HumanEval Overfitting" class="teaser-image center" width="100%"
                height="100%" />
            </div>
            <div class="columns is-centered">
              <img src="./images/exp_acb-lite.png" alt="HumanEval Overfitting" class="teaser-image center" width="100%"
                height="100%" />
            </div>
            <div class="columns is-centered">
              <img src="./images/exp_acb-comp.png" alt="HumanEval Overfitting" class="teaser-image center" width="100%"
                height="100%" />
            </div>
            <p>
              
            </p>
          </div>
        </div>
      </div>
</section>
<section class="section">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Further Analysis</h2>
          <div class="content has-text-justified">
            <div class="columns is-centered">
              <img src="./images/popu_vs_longtail.png" alt="HumanEval Overfitting" class="teaser-image center" width="90%"
                height="80%" />
            </div>
            <p>
              The performance difference between various models is small for popular languages, but large for low-resource languages.
            </p>
          </div>
          <div class="content has-text-justified">
            <div class="columns is-centered">
              <img src="./images/multi_logic.png" alt="HumanEval Overfitting" class="teaser-image center" width="90%"
                height="80%" />
            </div>
            <p>
              The performance of LLMs declines when faced with multi-logic programming problems.
            </p>
          </div>
          <div class="content has-text-justified">
            <div class="columns is-centered">
              <img src="./images/scaling.png" alt="HumanEval Overfitting" class="teaser-image center" width="90%"
                height="80%" />
            </div>
            <p>
              LLMs exhibit parameter and test-time sampling scaling law on AutoCodeBench.
            </p>
          </div>
          <div class="content has-text-justified">
            <div class="columns is-centered">
              <img src="./images/refine.png" alt="HumanEval Overfitting" class="teaser-image center" width="90%"
                height="80%" />
            </div>
            <p>
              The feedback provided by our multilingual sandbox can guide the model to refine its code.
            </p>
          </div>
        </div>
      </div>
</section>

<!--
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code></code></pre>
    </div>
  </section>
-->
  <footer class="footer">
    <div class="container">

      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content">
            <!-- <p>
              Please reach out to <em>jasonchou9877@gmail.com</em> for questions or feedback on AutoCodeBench. Finally, AutoCodeBench provides one axis of LLM coding evaluations and we recommend the following leaderboards for measuring code LM ability on various coding tasks, such as <a href="https://artifactsbenchmark.github.io/">ArtifactsBench Leaderboard</a>, <a href="https://mceval.github.io/">McEval Leaderboard</a>, <a href="https://livecodebench.github.io/leaderboard.html">LiveCodeBench Leaderboard</a>, <a href="https://evalplus.github.io/leaderboard.html">EvalPlus Leaderboard</a>, and <a href="https://huggingface.co/spaces/bigcode/bigcode-models-leaderboard">BigCode Models Leaderboard</a>.
            </p> -->
            <p>
              The source code from this website is borrowed from <a
                href="https://github.com/LiveCodeBench/livecodebench.github.io">LiveCodeBench</a>!
            </p>
          </div>
        </div>
      </div>
    </div>
  </footer>
</body>

</html>
